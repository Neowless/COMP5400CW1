
# Part One

## Question 1 

### Fitness Plot of the Mice as a Function of the Genertion Count 
<div align=center><img width="500" src="https://raw.githubusercontent.com/Neowless/COMP5400CW1/e1373e0b9de5c8d6b2b86aaf0ce66d0b625631d2/Question1/0-400.svg"/></div>

<div align=center><text>Figure 1. Average and Best Fitness versus Generation Count</text></div>

The simulation results are exported in the [`Question1/Mice.pop`](https://github.com/Neowless/COMP5400CW1/blob/main/Question1/Mice.pop), the data is extracted in [`Question1/question_1.mat`](https://github.com/Neowless/COMP5400CW1/blob/main/Question1/question_1.mat), the plots are generated by MATLAB 2021b, the scripts for generating the plots is [`Question1/Question1.m`](https://github.com/Neowless/COMP5400CW1/blob/main/Question1/Question1.m).
***
### Reasons Why Choosing This Range

The simulation was terminated after 3,000 generations to obtain enough data. [Figure 2](https://raw.githubusercontent.com/Neowless/COMP5400CW1/e1373e0b9de5c8d6b2b86aaf0ce66d0b625631d2/Question1/0-3000.svg) shows the whole range of the data.


<div align=center><img width="500" src="https://raw.githubusercontent.com/Neowless/COMP5400CW1/e1373e0b9de5c8d6b2b86aaf0ce66d0b625631d2/Question1/0-3000.svg"/></div>

<div align=center><text>Figure 2. Average and Best Fitness Versus Generation Count Whole Range</text></div>

* For the generation count range. In the generation domain from 0 to 150, the values of average fitness are highly irregular. In the range of 150-400, the average fitness numbers increase non-linearly. After 400 generations, the average fitness of the mice becomes stable around 0.008. The best fitness value also has similar characteristics. The generation range for both fitness are **0-400**
* For the fitness range. Considering the noise level and representive generation range. 

## Question 2

The mice evolves fatser, smarter and more efficient seeking the cheese over evolutionary time. The specific behaviours in explained in [Table 1]()

| Generation Count | Behaviour | 
| :-:  | --- |
| 0    | The mice move randomly and slowly, most of them are circling, only a few of the mice are moving at a relative faster speed in a relative straight line. The mice rarely obtain the cheese.| 
|   300   | The mice increase the speed. A few of mice’s movement show regular rules aiming at the cheese. However, the whole specie’s behaviours are irregular. After finishing one cheese, the mice just keep the previous direction. Some of the mice obtain the cheese. | 
|    500   | The behaviour does not change a lot, but the moving speed of the mice increase a little. Some of the mice are competing for one cheese.|
| 1000 | All of the mice are moving at a relative high speed, the mice are divided into many groups, each group usually competing for one cheese, after finishing one cheese, the mice are really sensitive to the nearest cheese and change its direction to obtain another cheese. | 
| 4000 | The mice started to rotate on the spot to evaluate the distances of the cheese around it which is a more efficient way to decide the behaviour. |

<div align=center><text>Table 1. Mice Behaviours in Different Generations</text></div>

## Question 3

### Discrition of the Fitness Function Used by the Mice

The fitness used by the Mice is in [`Question1/mouse.cc`](https://github.com/Neowless/COMP5400CW1/blob/main/Question1/mouse.cc) line 136-143.

``` C++
	// The EvoMouse's fitness is the amount of cheese collected, divided by
	// the power usage, so a mouse is penalised for simply charging around
	// as fast as possible and randomly collecting cheese - it needs to find
	// its target carefully.
	virtual float GetFitness()const
	{
		return This.cheesesFound > 0 ? static_cast<float>(This.cheesesFound) / This.DistanceTravelled.as<float>() : 0;
	}
}
```
The fitness of each mouse is obtained this `GetFitness()` function. There are two vairables in this function, `This.cheesesFound` indicates the cheeses found by the mouse in this generation simulation, and `This.DistanceTravelled.as` represents the distance the mouse travled in this generation.

If the mouse found the cheese, its fitness value equals to the amount of the cheese divided by the distance it travled, or the fitness value equals to 0.
ß
In order to train the mice forming a efficient way to find the cheese, the distance travled by the mouse determins the power consumption influencing the fitness value.
*** 

### Experiment with Different Fitness Functions Case 1

In case 1, the cheese number and the travled distance were changed irrelevant to the fitness function.

``` C++
	virtual float GetFitness()const
	{
		return This.cheesesFound > 0 ? 0: 0;
	}
}
```
When the simulation started, the behaviour of the mice is similar to the original fitness function ones.

With the increment of the simulation generation count, the behaviour becomes more random and caotic. The performance of the mice deteriorated.

### Experiment with Different Fitness Functions Case 2

In case 2, the fitness value and the amount of the cheese collected has first order linear relationship. The fitnesee equals to the amount of the cheese divided by 100.

``` C++
	virtual float GetFitness()const
	{
		return This.cheesesFound > 0 ? static_cast<float>(This.cheesesFound)/100 /: 0;
	}
}
```
When the simulation started, the behaviour of the mice is similar to the original fitness function ones.

With the increment of the simulation generation count, the behaviour becomes similar to the original fitness function, but the evololution speed decrease a lot. The performance of the mice deteriorated.

### Experiment with Different Fitness Functions Case 3

In case 3, the fitness value and the travled distance has first order linear relationship. The fitnesee equals to the travled distance of the mouse divided by 1000.

``` C++
	virtual float GetFitness()const
	{
		return This.cheesesFound > 0 ? This.DistanceTravelled.as<float>()/10000 /: 0;
	}
}
```
When the simulation started, the behaviour of the mice is similar to the original fitness function ones.

With the increment of the simulation generation count, speed of the mice increased a lot, and the mice just move directly rather than change its direction. The performance of the mice deteriorated.

The fitness function determines the **trend** and **efficiency** of the evolution.


*** 
### Parameters in Genetic Algorithm

The fitness used by the Mice is in [`Question1/mouse.cc`](https://github.com/Neowless/COMP5400CW1/blob/main/Question1/mouse.cc) line 159-185.

``` C++
class MouseSimulation : public Simulation
{
	GeneticAlgorithm<EvoMouse> theGA;
	Population<EvoMouse> theMice;
//	Group<Mouse> theMice;
	Group<Cheese> theCheeses;

public:
	MouseSimulation():
	theGA(0.7f, 0.05f),	// Crossover probability of 0.7, mutation probability of 0.05
//	theMice(30),		// 30 mice are in the population.
	theMice(30, theGA), // 30 mice are in the population.
	theCheeses(30)		// 30 cheeses are around at one time.
	{
		// We're using a rank selection method. Consult the BEAST
		// documentation for GeneticAlgorithm, the ar23 course slides or
		// a good book on GAs for more details.
		This.theGA.SetSelection(GA_RANK);
		// The ranking selection pressure is set to 2.
		This.theGA.SetParameter(GA_RANK_SPRESSURE, 2.0);

		This.SetTimeSteps(100);

		This.Add("Mice", This.theMice);
		This.Add("Cheeses", This.theCheeses);
	}
};
```

|  Parameters |  Source Code |  Influence |
|:-:|---|---|
|  Crossover Probability | `theGA(0.7f, 0.05f)`  | The core in the evolution of nature is played by the crossover of biological genes. Similarly, The core in genetic algorithms is played by the crossover operator of genetic operations. A crossover is an operation in which parts of the structure of two parent individuals are replaced and recombined to create a new individual. By crossover, the search power of genetic algorithms is improved by leaps and bounds.  |
| Mutation Probability  |  `theGA(0.7f, 0.05f)` |  The mutation operator is applied to change the value of a gene at some locus of a string of individuals in a population. When a genetic algorithm has approached the neighbourhood of the optimal solution through the crossover operator, this local stochastic search capability of the variation operator can be used to accelerate convergence to the optimal solution. The variation operator maintains population diversity to prevent immature convergence. |
| Selection Option |  `This.theGA.SetSelection(GA_RANK)` |  The rank proportional selection of the invidual is used, preventing one or twooverwhelmingly fit individuals in a population from dominating the nextgeneration. So if in a population of 3 individuals you had scores of(2, 3, 400), rank selection would convert these to (0.167, 0.333, 0.5). |
|  Ranking Selection Pressure | `This.theGA.SetParameter(GA_RANK_SPRESSURE, 2.0)`  |  When the pressure is low, we have relatively few randomly selected individuals, so that each individual faces less competitive pressure and thus has a higher probability of being selected. |
|  Simulation Time |  `This.SetTimeSteps(100)` | The simulation time determines the amount of the total behaviours in each generation  |

<div align=center><text>Table 2. Parameters in Genetic Algorithms</text></div>

## Question 4
The scripts for generating the plots and data is [`Question4/Question4.m`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/Question4.m).
### Performance Criterions and Evaluation

The fitness function should be evaluated in different aspects, the evolution time and final performance.

In this section, the original fitness function is the original fitness function applied in the [`Question4/mouse.cc`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/mouse.cc) line 136-143. The fitness equals to the amount of cheese collected, divided by the distance it traveld.

``` C++
	// The EvoMouse's fitness is the amount of cheese collected, divided by
	// the power usage, so a mouse is penalised for simply charging around
	// as fast as possible and randomly collecting cheese - it needs to find
	// its target carefully.
	virtual float GetFitness()const
	{
		return This.cheesesFound > 0 ? static_cast<float>(This.cheesesFound) / This.DistanceTravelled.as<float>() : 0;
	}
}
```

The new fitness function refers to [`Question4/mouse_new.cc`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/mouse_new.cc) line 136-14. The fitness equals to the amount of cheese collected.

``` C++
	// The EvoMouse's fitness is the amount of cheese collected.
	virtual float GetFitness()const
	{
		return This.cheesesFound > 0 ? static_cast<float>(This.cheesesFound) : 0;
	}
}
```

**Evolution Time**

Evolution time is defined as the generation count the simulation took to make  the fitness value stable. Less generation amount it takes, better the fitness function it will be.

<div align=center><img width="500" src="https://raw.githubusercontent.com/Neowless/COMP5400CW1/fffcdf33f613da2568e052ff695a85c4b2b8b20c/Question4/Converge_Compare_Functions.svg"/></div>

<div align=center><text>Figure 3. Convergenge of Different Fitness Function Comapre </text></div>

It is easy to indicate the original fitness function can converge faster than the new fitness function, which means the original fitness function is better than the new fitness function in this aspect.

**Stability of Average Fitness Value**

This is defined by the average fitness value's stability and noise level. Healthier specie has more stable average fitness value.

Dispersion indicates the stability of the average fitness value. Because of the amplitude of average fitness values is not the same in different fitness function, the dispersion is measured by the SNR (Signal-to-noise ratio), assuming the mean value of the average fitness values is the original signal after convergence. The results are exported in the MATLAB command window.

```
SNR of original fitness function -0.1783
SNR of new fitness function -0.0682
```
The original fitness function has larger SNR which means the relevant noise level in the original fitness function's average fitness value is lower. The original fitness function is better


**Cheese Allocation**

This is defined by the  which defined by the standard deviation of all the fitness values after 1000 generations of evolution. Smaller standart deviation indicates the fitness function has better performance

However, I am not familiar with C++, I tried to modify the BEAST but it was not successful.


*** 
### Different Sensor Configurations

In [`Question4/mouse.cc`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/mouse.cc), line 111-120 the `EvoMouse` is applied in the simulation. The original `EvoMouse` is using the `NearestAngleSensor`.

```C++
	EvoMouse(): cheesesFound(0)
	{
		This.Add("angle", NearestAngleSensor<Cheese>());
// An alternative to the NearestAngleSensor is the Proximity Sensor, which
// gives less precise directional information, but does let the mouse know
// how far away the cheese is.
//		This.Add("proximity", ProximitySensor<Cheese>(PI/8, 80.0, 0.0));
		This.InitRandom = true;
		This.InitFFN(4);
	}
```

`NearestAngleSensor` is described in [`Question4/sensor.h`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/sensor.h). This sensor provides precise angular information but it does not let the mouse know how far the cheese is.

```C++
Sensor* NearestAngleSensor()
{
	Sensor* s = new Sensor(Vector2D(0.0, 0.0), 0.0);
	s->SetMatchingFunction(new MatchKindOf<T>);
	s->SetEvaluationFunction(new EvalNearestAngle(s, 1000.0));
	s->SetScalingFunction(new ScaleLinear(-PI, PI, -1.0, 1.0));
	
	return s;
}
```

I tested the `ProximitySensor` as well, the codes for different sensor configurations is below. The Angle and Range in [Table 3]() are the parameters with the same name in `ProximitySensor<Cheese>(Angle, Range, 0.0))`.

| Serial Number |  Angle |  Range | File |
|:-:|:-:|:-:|---|
|1| 2*pi | 50 | [`Question4/mouse_sensor1.cc`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/mouse_sensor1.cc) |
|2| pi/3 | 50 | [`Question4/mouse_sensor2.cc`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/mouse_sensor2.cc)  |
|3| pi/4 | 50 |  [`Question4/mouse_sensor3.cc`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/mouse_sensor3.cc) |
|4| pi/4 | 100 |  [`Question4/mouse_sensor4.cc`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/mouse_sensor4.cc) |
|5| pi/4 | 200 |  [`Question4/mouse_sensor5.cc`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/mouse_sensor5.cc) |
|6| pi/4 | 200 |  [`Question4/mouse_sensor6.cc`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/mouse_sensor6.cc) |
|7| pi/6 | 50 |  [`Question4/mouse_sensor7.cc`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/mouse_sensor7.cc) |
|8| pi/8 | 50 |  [`Question4/mouse_sensor8.cc`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/mouse_sensor8.cc) |


<div align=center><text>Table 3. ProximitySensor Configurations</text></div>

```C++
	EvoMouse(): cheesesFound(0)
	{
//		This.Add("angle", NearestAngleSensor<Cheese>());
// An alternative to the NearestAngleSensor is the Proximity Sensor, which
// gives less precise directional information, but does let the mouse know
// how far away the cheese is.
		This.Add("proximity", ProximitySensor<Cheese>(Angle, Range, 0.0));
		This.InitRandom = true;
		This.InitFFN(4);
	}
```


`ProximitySensor` is described in [`Question4/sensor.h`](https://github.com/Neowless/COMP5400CW1/blob/main/Question4/sensor.h). This sensor provides less precise directional information but it let the mouse know how far the cheese is.

```C++
Sensor* ProximitySensor(double scope, double range, double orientation)
{
	Sensor* s = new BeamSensor(scope, range, Vector2D(0.0, 0.0), orientation);
	s->SetMatchingFunction(new MatchKindOf<T>);
	s->SetEvaluationFunction(new EvalNearest(s, Range));
	s->SetScalingFunction(new ScaleLinear(0.0, range, 1.0, 0.0));
	
	return s;
}
```

*** 
### Sensor Experiment

All of the sensor experiment are using the same original fitness function, so the mean value of the average fitness function is comparable. The sensor configuration with higher mean value after convergence has better perfomance. SNR is also introduced to evaluate the stability.

The results are exported in the MATLAB command window. 

```Matlab
SNR of original sensor configuration -0.1783
SNR of sensor configuration 1 -0.4143
SNR of sensor configuration 2 -0.2334
SNR of sensor configuration 3 -0.3790
SNR of sensor configuration 4 -0.3124
SNR of sensor configuration 5 -0.4421
SNR of sensor configuration 6 -0.3589
SNR of sensor configuration 7 -0.2482314
SNR of sensor configuration 8 -0.4421
Mean Value of original sensor configuration 0.0077
Mean Value of sensor configuration 1 0.0009
Mean Value of sensor configuration 2 0.0031
Mean Value of sensor configuration 3 0.0033
Mean Value of sensor configuration 4 0.0024
Mean Value of sensor configuration 5 0.0021
Mean Value of sensor configuration 6 0.0027
Mean Value of sensor configuration 7 0.0022
Mean Value of sensor configuration 8 0.0021
```

|Configuration Serial Number|Mean Value|SNR|
|:-:|:-:|:-:|
|Original|0.0077|-0.1783|
|1|0.0009|-0.4143|
|2|0.0031|-0.2334|
|3|0.0033|-0.3790|
|4|0.0024|-0.3124|
|5|0.0021|-0.44|
|6|0.0027|-0.36|
|7|0.0022|-0.25|
|8|0.0021|-0.44|

<div align=center><text>Table 4. Different Configurations Sensor Experiment Result</text></div>

<div align=center><img width="500" src="https://raw.githubusercontent.com/Neowless/COMP5400CW1/7c43248f6b641288ed96f66d0d2178889036db53/Question4/Compare_All_Sensors.svg"/></div>

<div align=center><text>Figure 4. Average Fitness of Different Sensor Configuration </text></div>

it is easy to indicate that, baesed on the mean values and amplitude plot, the final performancesthe `ProximitySensor` in these configurations are not as good as the `NearestAngleSensor`. Meanwhile, the `ProximitySensor` also has larger SNR, which means the `ProximitySensor`'s stability is better than others.

As for the `ProximitySensor`.

<div align=center><img width="500" src="https://raw.githubusercontent.com/Neowless/COMP5400CW1/43a3f5f1843adc73d6936a4859776dd72f1129e2/Question4/Different_Angle.svg"/></div>

<div align=center><text>Figure 5. Average Fitness of Different Angle Configuration </text></div>

<div align=center><img width="500" src="https://raw.githubusercontent.com/Neowless/COMP5400CW1/5f2889c13b3ea22f1af94e1234957b8d647b03d2/Question4/Different_Range.svg"/></div>

<div align=center><text>Figure 6. Mean Value of Average Fitness of Different Range Configuration </text></div>

Based on [Figure 5]('https://raw.githubusercontent.com/Neowless/COMP5400CW1/dbfff039cdf6e68583c0211b3d81faa032ffa75d/Question4/Mean_Different_Angle.svg') and [Table 4](), it is easy to summarize that, with the increment of the angle, the performance of the sensor may increase, and converge faster. Based on [Figure 6]('https://raw.githubusercontent.com/Neowless/COMP5400CW1/5f2889c13b3ea22f1af94e1234957b8d647b03d2/Question4/Different_Range.svg') and [Table 4](), larger range has better performance.

*** 
### Reasons Behind Experiments
The main difference of these two types of sensor is about the field of view of the mouse, which enable the mouse to sense and explore the cheese around it. With larger range or larger field of view, the mouse can sense the cheese better and collect more cheese. 


## Question 5

### Review on Genetic Algorithms
Genetic algorithms emulate the natural evolutionary process to find the optimal solution, applying the principles of selection and variation from Darwinian evolutionary theory. Directed selection, followed by undirected variation, reflects the fitness of each generation of individuals according to a fitness function that reflects the target, thus performing a selection operation followed by a genetic iteration that produces individuals with a new combination of genes.[1] [2]

The process of genetic algorithms is in fact a process similar to biological evolution in biology, in which at each generation in a genetic algorithm, individuals are selected according to the size of their fitness in the problem domain and, with the help of genetic operators for combinatorial crossover and subjective and objective variation, a population representing the new set of solutions is evolved. This process is performed cyclically until the optimisation criterion is satisfied. Finally, the last generation of individuals is decoded to generate a near-optimal solution.[3]
*** 
### Behaviour of the Mice
Collective behavior is the result of interaction and influence of each individual in the whole species, as for the mice simulation, the many small groups of mice usually compete for one cheese which is the best solution for the strongest individual or genetic clip. However, considering the reality, this behavior is not the best approach to select the best genetic for the whole species, especially considering the equality of cheese allocation. 
*** 
### Mice Collective Behaviour
After southands of simulation, some the mice starts to follow other mice as groups to collect cheese rather than sense and explore the chheese on theri own. I regard this as an evidence of collective behaviour.


# Part Two

## Question 6
Collegue Name:


## Question 7

| Generation Count | Predator Behaviour | 
| :-:  | --- |
|   0     |  | 
|   10    |  | 
|   50    |  | 
|   100   |  |
|   1000  |  |
|   5000  |  |


<div align=center><text>Table 5. Predator Behaviours in Different Generations</text></div>

| Generation Count | Prey Behaviour | 
| :-:  | --- |
|   0     |  | 
|   10    |  | 
|   50    |  | 
|   100   |  |
|   1000  |  |
|   5000  |  |

<div align=center><text>Table 6. Prey Behaviours in Different Generations</text></div>

## Question 8

# Part Three

## Question 9

### Definitions of Intelligence

The subject, in perceiving such of the purposive target object, produces a cognition that the other party is able to process, has the capacity to process, or has the corresponding function, and is referred to as intelligence. From an informatics perspective, this purposeful processing of intelligence is also a process of processing information, which derives its processing logic from the extraction and application of objective laws and drives. Intelligence can therefore also be seen as a manifestation of the use of knowledge. Intelligence can also be used as a general term for the ability to develop things according to a system of inertia without external forces, whereas purposeful processing changes the original direction of development, as if some force is generated. Different things have different processing logics, i.e. they have different purposes, ranging from the overly simple, such as conditioned reflexes, to the overly complex, where simple logics are stitched together, linked, nested, and combined to create a variety of abilities, such as perception, memory, imagination, thinking, attention, rallying, cohesion, execution, etc. However, the generalised titles can be summarised.

There are categories of intelligence, there are sizes, and the various intelligences can co-exist, depend on each other, complement each other, be connected, or even be mutually exclusive. Any combination of them constitutes a wide range of intelligences. From automatic doors with a single function to automated production lines with complex functions; from micro-organisms with the capacity to grow, reproduce and adapt, to human beings of all kinds, including groups of people, such as units, groups, organisations, nations, societies and human races, and even elementary particles and cosmic stars that can bounce off, deform or disintegrate on impact. From a rigid body with intelligence infinitely close to zero, to the quantification of the extremes of each human ability, a full-dimensional radar map can be constructed, then the hypothetical human, which sets all the extremes of human ability, represents the highest standard of the current level of human intelligence, which is also the highest standard of intelligence of known species, and can be tentatively called standard intelligence. Standard intelligence will continue to improve as humans explore, dig, and accumulate new knowledge.

Since its formal introduction in 1956, artificial intelligence has been given the ultimate goal of creating a level of intelligence like that of a human being. This is where scientists from different fields converged. Starting with the structure, function and role of the human brain, they formed three mainstream schools of thought, corresponding to connectionism, symbolism and behaviourism respectively.

Brain-like intelligence is a continuation of connectionism, a vision of artificial intelligence proposed in the late 1980s, in which they hoped to study the working mechanism of the human brain and simulate a robot with the same ability to think and learn as humans. It currently relies on two main techniques: deep learning and reinforcement learning.

Cognitive intelligence was developed out of the field of computing and is pretty much a continuation of symbolism. They believe that there are three stages to achieve artificial intelligence: computational intelligence, perceptual intelligence and cognitive intelligence, where cognitive intelligence mainly addresses the ability to understand and actively think, and is currently popularly divided into language comprehension, analytical reasoning and personality emotion.

General intelligence is machine intelligence that has general human intelligence and can perform any intellectual task that humans can perform. It is aimed at passing the Turing test, a sort of continuation of behaviourism, and is currently mostly in the academic discussion stage and simulation.

The human brain is a very sophisticated system, from the development of the fertilised egg to adulthood, and any slight deficiency in it, whether in the innate neurological system or in education and training, may result in mental retardation. The human brain is a very sophisticated system, from the spermatozoa to the adult.

One of the simplest and most economical ways to solve this problem is to strengthen self-learning ability, so that the intelligences can make up for their lack of ability through self-learning, thus achieving an overall increase in intelligence level. The strength of intelligence is relative, as long as there is self-learning ability it can change from weak to strong, so strong intelligence does not mean strong intelligence, but specifically refers to having the ability to actively acquire knowledge, i.e. self-learning ability, which can strengthen itself, and this is the only difference between strong intelligence and weak intelligence.

# References

[1] Debreuve, E., et al. "Using the shape gradient for active contour segmentation: from the continuous to the discrete formulation." *Journal of Mathematical Imaging and Vision* 28.1 (2007): 47-66.

[2] Sridevi, T., and S. Sameen Fatima. "Digital image watermarking using genetic algorithm in DWT and SVD transform." (2013): 485-490.

[3] Mitchell, Melanie. *An introduction to genetic algorithms*. MIT press, 1998.